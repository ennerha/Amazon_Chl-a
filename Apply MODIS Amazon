# ============================================================
# AMAZÔNIA — MODIS Pipeline NATIVO (rápido) — Lotes de 3 meses
#  • 100% nativo no sistema do MODIS (sinusoidal ~463 m)
#  • Sem reprojeção no Earth Engine e SEM reprojeção local
#  • Sem exclusão de dados/arquivos (mantém tudo que gerar)
#  • Terra+Aqua adaptativo, tiles grandes, paralelismo
#  • Saída: GeoTIFF nativo (sinusoidal) com photometric=MINISBLACK
#  • Visual rápido (preview) + média mensal (mg m^-3)
#  • Persistência no Google Drive por ANO/MÊS; arquivos com data MM.DD.AAAA
#  • Execução em LOTES: processa só os PRÓXIMOS N meses pendentes (BATCH_SIZE)
# ============================================================

import os, io, zipfile, time, warnings, sys, subprocess, importlib, json, pickle, logging, shutil
from pathlib import Path
import numpy as np
import matplotlib; matplotlib.use("Agg")
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from calendar import monthrange
from datetime import datetime

# ---------------------------------- Auto-instalação leve ----------------------------------
def _ensure(pkg, imp=None):
    name = imp or pkg.split('==')[0].split('>=')[0]
    try:
        importlib.import_module(name)
    except Exception:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", pkg])

for pkg, imp in [
    ("earthengine-api>=1.0.0","ee"),
    ("rasterio>=1.3.9","rasterio"),
    ("geopandas>=0.14","geopandas"),
    ("shapely>=2.0","shapely"),
    ("fiona>=1.9","fiona"),
    ("pyproj>=3.5","pyproj"),
    ("joblib>=1.2","joblib"),
    ("requests>=2.31","requests"),
    ("tqdm>=4.66","tqdm"),
]:
    try:
        importlib.import_module(imp)
    except Exception:
        _ensure(pkg, imp)

import ee, requests, joblib, geopandas as gpd, fiona, rasterio as rio
from rasterio.merge import merge as rio_merge
from rasterio.warp import transform_geom
from rasterio.features import rasterize
from shapely.geometry import (box, mapping, Polygon, MultiPolygon, GeometryCollection)
from shapely.ops import unary_union
from shapely.validation import make_valid
from tqdm import tqdm

warnings.filterwarnings("ignore")
logging.getLogger("rasterio._env").setLevel(logging.ERROR)
os.environ["CPL_DEBUG"] = "OFF"
os.environ["GEOPANDAS_IO_ENGINE"] = "fiona"   # força engine fiona (recria .shx e evita pyogrio aqui)

# ---------------------------------- Google Drive (Colab) ----------------------------------
try:
    import google.colab  # type: ignore
    IN_COLAB = True
except Exception:
    IN_COLAB = False

if IN_COLAB:
    from google.colab import drive  # type: ignore
    try:
        drive.mount('/content/drive', force_remount=True)
    except Exception:
        pass

# Raiz persistente no Drive (ajuste se quiser outra pasta)
DRIVE_ROOT = Path(os.environ.get("DRIVE_ROOT", "/content/drive/MyDrive/amazonia_modis_artifacts"))
DRIVE_ROOT.mkdir(parents=True, exist_ok=True)

# Inputs persistentes
INPUT_DIR = DRIVE_ROOT / "inputs"; INPUT_DIR.mkdir(parents=True, exist_ok=True)
SHAPE_DIR = INPUT_DIR / "shapes"; SHAPE_DIR.mkdir(parents=True, exist_ok=True)
MODEL_DIR = INPUT_DIR / "models"; MODEL_DIR.mkdir(parents=True, exist_ok=True)

def _ensure_from_legacy(src: Path, dst: Path):
    if (not dst.exists()) and src.exists():
        dst.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(src, dst)
        print(f"[INFO] Entrada copiada para o Drive: {src} -> {dst}")

# ---------------------------------- CONFIG ----------------------------------
# Intervalo total que você quer cobrir (2001 a 2024)
START_YEAR = 2001
END_YEAR   = 2024

# Quais meses de cada ano são elegíveis
MONTHS_TO_PROCESS = list(range(1, 13))   # todos os meses

# >>> NOVO: tamanho do LOTE por execução (processa só os próximos N meses pendentes)
BATCH_SIZE = int(os.environ.get("BATCH_SIZE", "3"))   # 3 por padrão

PAD_DAYS   = 2
COMPOSITE  = "median"

EE_PROJECT = os.environ.get("EE_PROJECT", "ee-enneralcantarabariri")

# Caminhos de entrada persistentes no Drive
SHP_PATH   = str(SHAPE_DIR / "Hydro_lakes_AM_basin.shp")
MODEL_PATH = str(MODEL_DIR / "amazonia_svr_global.pkl")
_ensure_from_legacy(Path("/content/Hydro_lakes_AM_basin.shp"), Path(SHP_PATH))
_ensure_from_legacy(Path("/content/artifacts_amazonia/amazonia_svr_global.pkl"), Path(MODEL_PATH))

# tiles grandes = menos chamadas HTTP (aumente se quiser ainda mais rápido)
TILE_DEG      = float(os.environ.get("TILE_DEG", "3.0"))

USE_TERRA_AQUA_ADAPTIVE = True
CLEAR_THRESHOLD = 0.45

# Modelo
PRED_INVERSE  = "ln1p"
NODATA_PRED   = -9999.0

# Paralelismo (ajuste conforme máquina)
MAX_WORKERS       = int(os.environ.get("DL_THREADS", "6"))        # downloads (I/O)
PROCESS_WORKERS   = int(os.environ.get("CPU_PROCS", "4"))         # predição (CPU)

# Pastas (placeholders — substituídas a cada mês no main)
ART_DIR  = DRIVE_ROOT
FEATURES_DIR = DRIVE_ROOT / "_placeholder_features"
TMP_DIR  = DRIVE_ROOT / "_placeholder_tmp"
PRED_DIR = DRIVE_ROOT / "_placeholder_pred"
PLOT_DIR = DRIVE_ROOT / "_placeholder_plots"
CACHE_DIR = DRIVE_ROOT / "cache"; CACHE_DIR.mkdir(exist_ok=True, parents=True)

SR_BANDS = ["sur_refl_b01","sur_refl_b02","sur_refl_b03",
            "sur_refl_b04","sur_refl_b05","sur_refl_b06","sur_refl_b07"]

def info(x): print(f"[INFO] {x}")
def err(x):  print(f"[ERROR] {x}")

# ---------------------------------- Helpers ROI (robustos p/ 2D/3D) ----------------------------------
def _ring_xy_closed(coords, ndigits=6):
    out = []
    for c in coords:
        if c is None:
            continue
        try:
            x = float(c[0]); y = float(c[1])
        except Exception:
            continue
        x = round(x, ndigits); y = round(y, ndigits)
        if not out or (x, y) != out[-1]:
            out.append((x, y))
    if not out:
        return []
    if out[0] != out[-1]:
        out.append(out[0])
    return out if len(out) >= 4 else []

def _poly_to_coords(poly, ndigits=6, max_vertices=5000):
    if poly is None or poly.is_empty or poly.exterior is None:
        return []
    def _rings_from(p):
        ext = _ring_xy_closed(list(p.exterior.coords), ndigits)
        if not ext:
            return []
        holes = []
        for r in p.interiors:
            rr = _ring_xy_closed(list(r.coords), ndigits)
            if rr:
                holes.append(rr)
        return [ext] + holes
    rings = _rings_from(poly)
    total = sum(len(r) for r in rings)
    tol = 0.0
    while rings and total > max_vertices:
        tol = max(tol*2, 1e-6)
        simp = poly.simplify(tol, preserve_topology=True)
        if simp is None or simp.is_empty or simp.exterior is None:
            break
        rings = _rings_from(simp)
        total = sum(len(r) for r in rings)
        if tol > 1e-2:
            break
    return rings

def multipolygon_to_ee_geojson(geom, ndigits=6, max_vertices=5000):
    if geom is None or geom.is_empty:
        return None
    if isinstance(geom, Polygon):
        polys = [geom]
    elif isinstance(geom, MultiPolygon):
        polys = list(geom.geoms)
    else:
        return None
    all_poly_rings = []
    for p in polys:
        rings = _poly_to_coords(p, ndigits, max_vertices)
        if rings:
            all_poly_rings.append(rings)
    if not all_poly_rings:
        return None
    if len(all_poly_rings) == 1:
        return {"type": "Polygon", "coordinates": all_poly_rings[0]}
    return {"type": "MultiPolygon", "coordinates": all_poly_rings}

def sanitize_polygonal(geom):
    if geom is None or geom.is_empty:
        return Polygon()
    try:
        geom = make_valid(geom)
    except Exception:
        geom = geom.buffer(0)
    polys = []
    if isinstance(geom, (Polygon, MultiPolygon)):
        polys = [geom] if isinstance(geom, Polygon) else list(geom.geoms)
    elif isinstance(geom, GeometryCollection):
        for gg in geom.geoms:
            if isinstance(gg, (Polygon, MultiPolygon)):
                polys.append(gg)
    if not polys:
        return Polygon()
    return unary_union(polys)

# ---------------------------------- EE init ----------------------------------
def ee_init():
    try:
        ee.Initialize(project=EE_PROJECT)
    except Exception:
        ee.Authenticate(auth_mode='notebook')
        ee.Initialize(project=EE_PROJECT)
    info(f"EE OK — project: {EE_PROJECT}")

# ---------------------------------- Processados (no Drive) ----------------------------------
def get_processed_months():
    processed = []
    if DRIVE_ROOT.exists():
        for year_dir in DRIVE_ROOT.iterdir():
            if not year_dir.is_dir():
                continue
            try:
                y = int(year_dir.name)
            except Exception:
                continue
            for month_dir in year_dir.iterdir():
                if not month_dir.is_dir():
                    continue
                try:
                    m = int(month_dir.name)
                except Exception:
                    continue
                pred_dir = month_dir / "pred"
                if not pred_dir.exists():
                    continue
                # aceita sufixo com data: amazonia_chla_YYYY-MM__MM.DD.AAAA.tif
                for f in pred_dir.glob(f"amazonia_chla_{y:04d}-{m:02d}*.tif"):
                    processed.append((y, m))
                    break
    return set(processed)

# ---------------------------------- ROI (cache + CRS robusto + fallback bbox) ----------------------------------
def load_roi_local():
    roi_cache = CACHE_DIR / "roi_cache.pkl"
    if roi_cache.exists():
        try:
            with open(roi_cache, 'rb') as f:
                obj = pickle.load(f)
            if isinstance(obj, (list, tuple)) and len(obj) == 4:
                roi_gdf, roi_geom, roi_bbox_ee, roi_ee = obj
                info(f"ROI carregada do cache (v2): {roi_geom.bounds}")
                return roi_gdf, roi_geom, roi_bbox_ee, roi_ee
            info("ROI cache em formato inesperado. Recriando...")
        except Exception as e:
            err(f"Falha ao ler cache da ROI ({e}). Recriando...")

    if not Path(SHP_PATH).exists():
        raise FileNotFoundError(f"Shapefile não encontrado: {SHP_PATH}")

    with fiona.Env(SHAPE_RESTORE_SHX='YES'):
        gdf = gpd.read_file(SHP_PATH, engine="fiona")

    # CRS robusto (shapefile sem .prj)
    if gdf.crs is None:
        info("Shapefile sem CRS; assumindo EPSG:4326 (WGS84).")
        gdf = gdf.set_crs("EPSG:4326")
    elif str(gdf.crs).upper() != "EPSG:4326":
        gdf = gdf.to_crs("EPSG:4326")

    geoms = []
    for geom in gdf.geometry:
        if geom is None or geom.is_empty:
            continue
        try:
            gv = make_valid(geom)
        except Exception:
            gv = geom.buffer(0)
        if not gv.is_empty:
            geoms.append(gv)

    if not geoms:
        raise ValueError("ROI sem geometrias válidas no shapefile.")

    uni_raw = unary_union(geoms)
    uni = sanitize_polygonal(uni_raw)
    xmin,ymin,xmax,ymax = uni.bounds
    roi_bbox_ee = ee.Geometry.Rectangle([xmin,ymin,xmax,ymax], "EPSG:4326", False)
    ee_geo = multipolygon_to_ee_geojson(uni)
    roi_ee = ee.Geometry(ee_geo, "EPSG:4326", False) if ee_geo else roi_bbox_ee

    roi_gdf = gpd.GeoDataFrame(geometry=[uni], crs="EPSG:4326")
    with open(roi_cache, 'wb') as f:
        pickle.dump((roi_gdf, uni, roi_bbox_ee, roi_ee), f)
    info(f"ROI bounds: {uni.bounds}")
    return roi_gdf, uni, roi_bbox_ee, roi_ee

# ---------------------------------- Tiles ----------------------------------
def tiles_rects(bounds, step_deg):
    xmin,ymin,xmax,ymax = bounds
    xs = np.arange(np.floor(xmin/step_deg)*step_deg, np.ceil(xmax/step_deg)*step_deg, step_deg)
    ys = np.arange(np.floor(ymin/step_deg)*step_deg, np.ceil(ymax/step_deg)*step_deg, step_deg)
    rects = []
    for x0 in xs:
        x1 = min(x0+step_deg, xmax)
        for y0 in ys:
            y1 = min(y0+step_deg, ymax)
            if x1<=x0 or y1<=y0:
                continue
            rects.append((float(x0), float(y0), float(x1), float(y1)))
    return rects

def filter_tiles_simple(roi_geom, rects):
    cand = [r for r in rects if box(*r).intersects(roi_geom)]
    info(f"Tiles válidos (intersecção ROI): {len(cand)}")
    return cand

# ---------------------------------- QA rápido+ ----------------------------------
def scale_qc_fast(img):
    sr = img.select(SR_BANDS).multiply(0.0001)
    band_names = img.bandNames()
    has_qc_500 = band_names.indexOf("sur_refl_qc_500m").neq(-1)
    has_state1 = band_names.indexOf("state_1km").neq(-1)

    def _mask_with_state_and_qc():
        qa = img.select("sur_refl_qc_500m")
        good_qc = qa.bitwiseAnd(3).lte(1)
        st = img.select("state_1km")
        cloud_state = st.bitwiseAnd(3)     # bits 0-1
        clear = cloud_state.eq(0)
        return sr.updateMask(good_qc.And(clear))

    def _mask_with_qc_only():
        qa = img.select("sur_refl_qc_500m")
        good_qc = qa.bitwiseAnd(3).lte(1)
        return sr.updateMask(good_qc)

    def _no_qc():
        return sr

    result = ee.Algorithms.If(
        has_state1, _mask_with_state_and_qc(),
        ee.Algorithms.If(has_qc_500, _mask_with_qc_only(), _no_qc())
    )
    return ee.Image(result).copyProperties(img, ['system:time_start'])

# ---------------------------------- Métricas e score ----------------------------------
def _valid_fraction(img, roi, band="sur_refl_b04"):
    valid = img.select(band).mask().rename('m')
    stats = valid.reduceRegion(ee.Reducer.mean(), roi, 1000, maxPixels=1e13)
    return ee.Number(stats.get('m'))

def _quality_score(img):
    band_names = img.bandNames()
    has_state1 = band_names.indexOf("state_1km").neq(-1)

    def with_state():
        st = img.select("state_1km")
        cloud_state = st.bitwiseAnd(3)
        score = (cloud_state.eq(0).multiply(1.0)
                 .add(cloud_state.eq(2).multiply(0.5))
                 .add(cloud_state.eq(1).multiply(0.0))
                 .add(cloud_state.eq(3).multiply(-1.0)))
        return score.rename("score")

    def no_state():
        b04 = img.select("sur_refl_b04")
        mn = ee.Number(0.01); mx = ee.Number(0.2)
        b04n = b04.subtract(mn).divide(mx.subtract(mn)).clamp(0,1)
        return ee.Image(1.0).subtract(b04n).rename("score")

    return ee.Image(ee.Algorithms.If(has_state1, with_state(), no_state()))

# ---------------------------------- Mosaico Terra+Aqua adaptativo ----------------------------------
def build_mosaic_month_adapt(roi_bbox_ee, year, month):
    start = ee.Date.fromYMD(year, month, 1)
    end   = start.advance(1, "month")
    if PAD_DAYS > 0:
        start = start.advance(-PAD_DAYS, "day")
        end   = end.advance(PAD_DAYS, "day")

    def coll(path):
        return (ee.ImageCollection(path)
                .filterDate(start, end)
                .filterBounds(roi_bbox_ee)
                .map(scale_qc_fast))

    try:
        terra = coll("MODIS/061/MOD09A1")
    except Exception:
        terra = coll("MODIS/006/MOD09A1")

    terra_mos = (terra.select(SR_BANDS).median() if COMPOSITE == "median"
                 else terra.select(SR_BANDS).mean()).clip(roi_bbox_ee)

    frac_terra = _valid_fraction(terra_mos, roi_bbox_ee)

    if not USE_TERRA_AQUA_ADAPTIVE:
        return terra_mos, frac_terra

    def with_combo():
        try:
            aqua = coll("MODIS/061/MYD09A1")
        except Exception:
            aqua = coll("MODIS/006/MYD09A1")
        both = terra.merge(aqua)
        scored = both.map(lambda im: ee.Image(im.addBands(_quality_score(im))))
        qm = scored.qualityMosaic("score").select(SR_BANDS)
        mos = qm if COMPOSITE == "median" else scored.select(SR_BANDS).median()
        return mos.clip(roi_bbox_ee)

    mosaic_final = ee.Image(ee.Algorithms.If(frac_terra.lt(CLEAR_THRESHOLD),
                                             with_combo(), terra_mos))
    return mosaic_final, frac_terra

# ---------------------------------- Features ----------------------------------
def _lin_interp(img_low, wl_low, img_high, wl_high, wl_target):
    frac = (wl_target - wl_low) / (wl_high - wl_low + 1e-12)
    return img_low.add(img_high.subtract(img_low).multiply(frac))

def build_features_image_fast(mosaic, feature_names):
    eps = ee.Image.constant(1e-12)
    zero_scalar = ee.Image.constant(0)

    base = {b: mosaic.select(b) for b in SR_BANDS}
    b03 = base.get("sur_refl_b03")
    b04 = base.get("sur_refl_b04")
    b01 = base.get("sur_refl_b01")

    Rrs_560 = b04
    Rrs_490 = _lin_interp(b03, 469.0, b04, 555.0, 490.0) if (b03 is not None and b04 is not None) else None
    Rrs_510 = _lin_interp(b03, 469.0, b04, 555.0, 510.0) if (b03 is not None and b04 is not None) else None
    Rrs_443 = (_lin_interp(b03, 469.0, b04, 555.0, 443.0).max(zero_scalar)
               if (b03 is not None and b04 is not None) else None)
    Rrs_620 = _lin_interp(b04, 555.0, b01, 645.0, 620.0) if (b01 is not None and b04 is not None) else None
    Rrs_665 = _lin_interp(b04, 555.0, b01, 645.0, 665.0) if (b01 is not None and b04 is not None) else None
    Rrs_709 = _lin_interp(b04, 555.0, b01, 645.0, 709.0) if (b01 is not None and b04 is not None) else None

    proxies = {"Rrs_443": Rrs_443, "Rrs_490": Rrs_490, "Rrs_510": Rrs_510,
               "Rrs_560": Rrs_560, "Rrs_620": Rrs_620, "Rrs_665": Rrs_665, "Rrs_709": Rrs_709}

    L1 = mosaic.select(SR_BANDS).reduce(ee.Reducer.sum()).add(eps)

    def pick(stem):
        table = {
            **proxies,
            "G_over_B": (b04.divide(b03.add(eps)) if (b04 is not None and b03 is not None) else None),
            "B_over_R": (b03.divide(b01.add(eps)) if (b03 is not None and b01 is not None) else None),
            "NDCI": ((Rrs_709.subtract(b01)).divide(Rrs_709.add(b01).add(eps))
                     if (Rrs_709 is not None and b01 is not None) else None),
        }
        return table.get(stem, None)

    bands = []
    zero_img = mosaic.select(0).multiply(0)

    for fname in feature_names:
        img = pick(fname)

        if img is None and fname.endswith("_norm560"):
            stem = fname[:-8]; b = pick(stem)
            if b is not None and Rrs_560 is not None:
                img = b.divide(Rrs_560.add(eps))
        elif img is None and fname == "norm_Rrs_L1":
            img = L1
        elif img is None and fname.endswith("_normL1"):
            stem = fname[:-7]; b = pick(stem)
            if b is not None:
                img = b.divide(L1)

        if img is None:
            img = zero_img

        bands.append(img.rename(fname))

    return ee.Image.cat(bands)

# ---------------------------------- Download (rápido: nativo sinusoidal) ----------------------------------
def download_tiles_parallel(feats_im, rects, tile_tag, native_scale, roi_ee=None):
    scale_val = float(native_scale)
    args = []
    for tid, rect in enumerate(rects):
        rect_ee = ee.Geometry.Rectangle(rect, proj="EPSG:4326", geodesic=False)
        region_ee = rect_ee if roi_ee is None else rect_ee.intersection(roi_ee, 1)
        out_tif = FEATURES_DIR / f"feats_{tile_tag}_t{tid:03d}.tif"
        args.append((feats_im, region_ee, str(out_tif), scale_val))

    def _dl(arg):
        img, region_ee, out_path, scale_use = arg
        params = {
            "region": region_ee,
            "scale": scale_use,          # sem 'crs' -> proj nativa (sinusoidal)
            "maxPixels": int(1e13),
            "format": "GEO_TIFF"
        }
        max_retries = 2
        for attempt in range(max_retries):
            try:
                url = img.getDownloadURL(params)
                r = requests.get(url, timeout=300, allow_redirects=True)
                r.raise_for_status()
                data = r.content
                if data[:2] == b'PK':
                    with zipfile.ZipFile(io.BytesIO(data)) as zf:
                        names = [n for n in zf.namelist() if n.lower().endswith(('.tif','.tiff'))]
                        if names:
                            with zf.open(names[0]) as zt, open(out_path, 'wb') as f:
                                f.write(zt.read())
                            return str(out_path)
                else:
                    with open(out_path, 'wb') as f:
                        f.write(data)
                    return str(out_path)
            except Exception as e:
                if attempt == max_retries - 1:
                    err(f"Download falhou após {max_retries} tentativas: {e}")
                else:
                    time.sleep(1)
        return None

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        results = list(tqdm(ex.map(_dl, args), total=len(args), desc="Downloading tiles"))
    return [r for r in results if r is not None]

# ---------------------------------- Predição ----------------------------------
def predict_tile_fast(args):
    path_tif, roi_geom, model_data = args
    try:
        with rio.open(path_tif) as ds:
            arr = ds.read().astype("float32")
            height, width = ds.height, ds.width
            transform = ds.transform
            crs = ds.crs

        finite_all = np.isfinite(arr).all(axis=0)

        try:
            geoms_tx = [transform_geom("EPSG:4326", crs.to_string(), mapping(roi_geom), precision=6)]
            roi_m = rasterize([(g,1) for g in geoms_tx],
                              out_shape=(height, width),
                              transform=transform,
                              fill=0,
                              all_touched=True, dtype="uint8").astype(bool)
        except Exception:
            roi_m = np.ones((height, width), dtype=bool)

        mask = finite_all & roi_m
        if not mask.any():
            return None

        B, H, W = arr.shape
        data = arr.reshape(B, -1).T
        valid_idx = mask.reshape(-1)

        y_log = np.full(data.shape[0], np.nan, dtype="float32")
        if valid_idx.any():
            X = data[valid_idx]
            finite = np.isfinite(X).all(axis=1)
            if finite.any():
                Xc = X[finite]
                valid_finite_idx = np.where(valid_idx)[0][finite]
                y_log[valid_finite_idx] = model_data["model"].predict(Xc).astype("float32")

        y_lin = np.expm1(y_log) if PRED_INVERSE == "ln1p" else y_log
        pred = y_lin.reshape(H, W).astype("float32")
        pred[~mask] = NODATA_PRED
        pred[~np.isfinite(pred)] = NODATA_PRED

        out_tile = TMP_DIR / f"pred_{Path(path_tif).stem}.tif"
        prof_out = {
            "driver": "GTiff",
            "height": H,
            "width": W,
            "count": 1,
            "dtype": "float32",
            "crs": crs,
            "transform": transform,
            "nodata": NODATA_PRED,
            "compress": "deflate",
            "photometric": "MINISBLACK"
        }
        with rio.open(out_tile, "w", **prof_out) as dst:
            dst.write(pred, 1)

        return str(out_tile)

    except Exception as e:
        err(f"Erro predição {path_tif}: {e}")
        return None

def predict_tiles_parallel(downloaded, roi_geom, M):
    predict_args = [(f, roi_geom, M) for f in downloaded]
    with ProcessPoolExecutor(max_workers=PROCESS_WORKERS) as executor:
        results = list(tqdm(executor.map(predict_tile_fast, predict_args),
                            total=len(predict_args), desc="Predicting tiles"))
    return [r for r in results if r is not None]

# ---------------------------------- Visualizações ----------------------------------
def preview_png_fast(tif_path):
    try:
        with rio.open(tif_path) as ds:
            arr = ds.read(1, out_shape=(max(1, ds.height//4), max(1, ds.width//4)))
            arr = np.ma.masked_equal(arr, ds.nodata)
        if arr.compressed().size == 0:
            return
        vmin, vmax = np.percentile(arr.compressed(), (5, 95))
        plt.figure(figsize=(6, 4))
        plt.imshow(arr, vmin=vmin, vmax=vmax, cmap="viridis")
        plt.colorbar(label="Chl-a (mg m$^{-3}$)", shrink=0.6)
        plt.title(Path(tif_path).name, fontsize=10)
        plt.axis('off')
        out = PLOT_DIR / f"preview_{Path(tif_path).stem}.png"
        plt.savefig(out, dpi=100, bbox_inches="tight")
        plt.close()
        info(f"Preview salvo em: {out}")
    except Exception as e:
        err(f"Preview error: {e}")

def compute_month_mean(tif_path, roi_geom):
    """Média mensal de Chl-a (mg m^-3) sobre a ROI — no CRS nativo."""
    try:
        with rio.open(tif_path) as ds:
            arr = ds.read(1)
            nodata = ds.nodata
            transform = ds.transform
            crs = ds.crs
            height, width = ds.height, ds.width
        try:
            geoms_tx = [transform_geom("EPSG:4326", crs.to_string(), mapping(roi_geom), precision=6)]
            roi_m = rasterize([(g,1) for g in geoms_tx],
                              out_shape=(height, width),
                              transform=transform,
                              fill=0,
                              all_touched=True, dtype="uint8").astype(bool)
        except Exception:
            roi_m = np.ones((height, width), dtype=bool)
        m = roi_m & np.isfinite(arr) & ((nodata is None) | (arr != nodata))
        if not m.any():
            return np.nan
        return float(arr[m].mean())
    except Exception as e:
        err(f"Falha ao calcular média mensal: {e}")
        return np.nan

def plot_month_mean(mean_value, ym_str):
    try:
        plt.figure(figsize=(4,3))
        plt.bar([ym_str], [mean_value])
        plt.ylabel("Chl-a (mg m$^{-3}$)")
        plt.title(f"Média mensal: {ym_str}")
        out = PLOT_DIR / f"mean_{ym_str}.png"
        plt.savefig(out, dpi=110, bbox_inches="tight")
        plt.close()
        info(f"Gráfico de média salvo em: {out}")
    except Exception as e:
        err(f"Falha ao plotar média: {e}")

# ---------------------------------- MAIN ----------------------------------
def main():
    start_time = time.time()
    ee_init()

    # Verificação de entradas persistentes
    if not Path(SHP_PATH).exists():
        raise FileNotFoundError(
            f"Shapefile não encontrado em {SHP_PATH}.\n"
            f"Coloque .shp/.shx/.dbf/.prj em: {SHAPE_DIR}/"
        )
    if not Path(MODEL_PATH).exists():
        raise FileNotFoundError(
            f"Modelo não encontrado em {MODEL_DIR}.\n"
            f"Coloque o .pkl em: {MODEL_DIR}/"
        )

    def _date_tag_last_day(year, month):
        # último dia do mês como "data" do produto (formato MM.DD.AAAA)
        last_day = monthrange(year, month)[1]
        return f"{month:02d}.{last_day:02d}.{year:04d}"

    # ROI pronta
    roi_gdf, roi_geom, roi_bbox_ee, roi_ee = load_roi_local()
    info(f"ROI pronta: {roi_geom.bounds}")

    # Modelo
    M = joblib.load(MODEL_PATH)

    # Tiles (use TILE_DEG maior p/ menos tiles)
    rects_all = tiles_rects(roi_geom.bounds, TILE_DEG)
    rects = filter_tiles_simple(roi_geom, rects_all)
    info(f"Processando tiles de {TILE_DEG}° — total: {len(rects)}")

    # Lista completa de meses-alvo (ano, mês)
    all_months = [(y, m) for y in range(START_YEAR, END_YEAR+1) for m in MONTHS_TO_PROCESS]

    # Meses já processados (no Drive)
    processed = get_processed_months()

    # PENDENTES na ordem cronológica
    months_pending = [(y, m) for (y, m) in all_months if (y, m) not in processed]

    if not months_pending:
        info("Nada a fazer — todos os meses do intervalo já estão processados.")
        return

    # >>> RECORTE DO LOTE (só os próximos N meses pendentes)
    batch = months_pending[:max(1, BATCH_SIZE)]
    info(f"Lote atual (até {BATCH_SIZE} meses): {batch}")

    for idx, (year, month) in enumerate(batch, 1):
        ym = f"{year:04d}-{month:02d}"
        date_tag = _date_tag_last_day(year, month)  # "MM.DD.AAAA"

        # Pastas por ANO/MÊS no Drive
        YEAR_DIR  = DRIVE_ROOT / f"{year:04d}"
        MONTH_DIR = YEAR_DIR / f"{month:02d}"
        YEAR_DIR.mkdir(parents=True, exist_ok=True)
        MONTH_DIR.mkdir(parents=True, exist_ok=True)

        # Redefinir destinos globais para este mês
        global ART_DIR, FEATURES_DIR, TMP_DIR, PRED_DIR, PLOT_DIR
        ART_DIR      = MONTH_DIR
        FEATURES_DIR = MONTH_DIR / "features"; FEATURES_DIR.mkdir(exist_ok=True, parents=True)
        TMP_DIR      = MONTH_DIR / "tmp";      TMP_DIR.mkdir(exist_ok=True, parents=True)
        PRED_DIR     = MONTH_DIR / "pred";     PRED_DIR.mkdir(exist_ok=True, parents=True)
        PLOT_DIR     = MONTH_DIR / "plots";    PLOT_DIR.mkdir(exist_ok=True, parents=True)

        info(f"=== {ym} === ({idx}/{len(batch)})")
        info(f"Armazenando no Drive: {MONTH_DIR}")

        # Arquivo final com sufixo de data (MM.DD.AAAA)
        out_final = PRED_DIR / f"amazonia_chla_{ym}__{date_tag}.tif"
        if out_final.exists():
            info(f"[{ym}] Já existe, pulando processamento.")
            preview_png_fast(out_final)
            mean_val = compute_month_mean(out_final, roi_geom)
            if np.isfinite(mean_val):
                info(f"[{ym}] MÉDIA mensal Chl-a: {mean_val:.3f} mg m^-3")
                plot_month_mean(mean_val, ym)
            # Manifest mesmo no pulo
            try:
                manifest = {
                    "year": year, "month": month, "date_tag": date_tag,
                    "paths": {
                        "features_dir": str(FEATURES_DIR),
                        "tmp_dir":      str(TMP_DIR),
                        "pred_dir":     str(PRED_DIR),
                        "plots_dir":    str(PLOT_DIR),
                        "cache_dir":    str(CACHE_DIR),
                        "mosaic_tif":   str(out_final),
                    },
                    "params": {
                        "PAD_DAYS": PAD_DAYS, "COMPOSITE": COMPOSITE,
                        "USE_TERRA_AQUA_ADAPTIVE": USE_TERRA_AQUA_ADAPTIVE,
                        "CLEAR_THRESHOLD": CLEAR_THRESHOLD,
                    },
                    "inputs": {
                        "shapefile": SHP_PATH,
                        "model": MODEL_PATH
                    },
                    "timestamp": datetime.now().isoformat()
                }
                with open((MONTH_DIR / f"manifest_{ym}__{date_tag}.json"), "w", encoding="utf-8") as f:
                    json.dump(manifest, f, ensure_ascii=False, indent=2)
            except Exception as _e:
                err(f"Manifest (pós-skip) falhou: {_e}")
            continue

        try:
            # 1) Mosaico adaptativo + features
            t0 = time.perf_counter()
            mosaic, frac_terra = build_mosaic_month_adapt(roi_bbox_ee, year, month)
            feats_im = build_features_image_fast(mosaic, M["features"])

            # scale nativo (~463 m)
            mosaic_proj = mosaic.projection()
            try:
                native_scale = float(mosaic_proj.nominalScale().getInfo())
            except Exception:
                native_scale = 463.3127
            info(f"[{ym}] EE mosaic+features (nativo) em {(time.perf_counter()-t0):.1f}s; scale≈{native_scale:.2f} m")

            # 2) Download paralelo (NATIVO; sem reprojetar no EE)
            t1 = time.perf_counter()
            tile_tag = f"{ym}__{date_tag}"
            downloaded = download_tiles_parallel(feats_im, rects, tile_tag, native_scale, roi_ee=roi_ee)
            info(f"[{ym}] Download: {(time.perf_counter()-t1):.1f}s; tiles OK: {len(downloaded)}")
            if not downloaded:
                err(f"[{ym}] Nenhum download bem-sucedido"); continue

            # 3) Predição paralela
            t2 = time.perf_counter()
            pred_tiles = predict_tiles_parallel(downloaded, roi_geom, M)
            info(f"[{ym}] Predição: {(time.perf_counter()-t2):.1f}s; tiles OK: {len(pred_tiles)}")
            if not pred_tiles:
                err(f"[{ym}] Nenhuma predição bem-sucedida"); continue

            # 4) Merge final — mantém CRS NATIVO (sinusoidal)
            t3 = time.perf_counter()
            srcs = [rio.open(p) for p in pred_tiles]
            mosaic_arr, mosaic_trans = rio_merge(srcs, nodata=NODATA_PRED)
            native_crs = srcs[0].crs
            for s in srcs:
                s.close()

            meta_native = {
                "driver": "GTiff",
                "height": mosaic_arr.shape[1],
                "width": mosaic_arr.shape[2],
                "count": 1,
                "dtype": mosaic_arr.dtype,
                "crs": native_crs,
                "transform": mosaic_trans,
                "nodata": NODATA_PRED,
                "compress": "lzw",
                "tiled": True,
                "photometric": "MINISBLACK",
                "blockxsize": 256,
                "blockysize": 256
            }
            with rio.open(out_final, "w", **meta_native) as dst:
                dst.write(mosaic_arr[0], 1)
            info(f"[{ym}] Merge (nativo): {(time.perf_counter()-t3):.1f}s")

            # 5) SEM LIMPEZA — mantém downloads, tiles previstos e mosaico final.

            # Visual e média mensal
            preview_png_fast(out_final)
            mean_val = compute_month_mean(out_final, roi_geom)
            if np.isfinite(mean_val):
                info(f"[{ym}] MÉDIA mensal Chl-a: {mean_val:.3f} mg m^-3")
                plot_month_mean(mean_val, ym)

            # Manifest final
            try:
                feats_list = sorted([str(p) for p in FEATURES_DIR.glob(f"feats_{ym}__{date_tag}_t*.tif")])
                preds_list = sorted([str(p) for p in TMP_DIR.glob(f"pred_feats_{ym}__{date_tag}_t*.tif")])
                manifest = {
                    "year": year, "month": month, "date_tag": date_tag,
                    "paths": {
                        "features_dir": str(FEATURES_DIR),
                        "tmp_dir":      str(TMP_DIR),
                        "pred_dir":     str(PRED_DIR),
                        "plots_dir":    str(PLOT_DIR),
                        "cache_dir":    str(CACHE_DIR),
                        "mosaic_tif":   str(out_final),
                        "features_tiles": feats_list,
                        "predicted_tiles": preds_list
                    },
                    "params": {
                        "PAD_DAYS": PAD_DAYS, "COMPOSITE": COMPOSITE,
                        "USE_TERRA_AQUA_ADAPTIVE": USE_TERRA_AQUA_ADAPTIVE,
                        "CLEAR_THRESHOLD": CLEAR_THRESHOLD,
                        "native_scale_m": native_scale
                    },
                    "inputs": {
                        "shapefile": SHP_PATH,
                        "model": MODEL_PATH
                    },
                    "timestamp": datetime.now().isoformat()
                }
                with open((MONTH_DIR / f"manifest_{ym}__{date_tag}.json"), "w", encoding="utf-8") as f:
                    json.dump(manifest, f, ensure_ascii=False, indent=2)
                info(f"Manifest salvo.")
            except Exception as _e:
                err(f"Manifest falhou: {_e}")

        except Exception as e:
            err(f"[{ym}] Erro: {e}")
            continue

    total_time = (time.time() - start_time) / 3600
    info(f"LOTE CONCLUÍDO! Meses processados: {len(batch)} — Tempo: {total_time:.2f} h")
    info("Para continuar, execute novamente esta célula: o próximo lote de meses pendentes será processado.")

# ---------------------------------- ENTRYPOINT ----------------------------------
if __name__ == "__main__":
    main()
