# ============================================================
# AMAZÔNIA — MODIS OTIMIZADO (2001–2024, TODOS OS MESES)
# • Processamento paralelo
# • Tiles maiores e otimizados
# • Cache inteligente
# • Skip de meses já processados
# • QA rápido+ com state_1km quando disponível
# • Proxies espectrais por interpolação (490/510/620/665/709)
# ============================================================

import os, io, zipfile, time, warnings, sys, subprocess, importlib, json, pickle
from pathlib import Path
import numpy as np
import matplotlib; matplotlib.use("Agg")
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import ee, requests, joblib
import geopandas as gpd
import fiona, rasterio as rio
from rasterio.merge import merge as rio_merge
from rasterio.warp import transform_geom
from rasterio.features import rasterize
from shapely.geometry import box, mapping
from shapely.ops import unary_union
from shapely.validation import make_valid
from tqdm import tqdm

# ---------------------- DEPENDÊNCIAS (auto-instalação opcional) ----------------------
def _ensure(pkg, imp=None):
    name = imp or pkg.split('==')[0].split('>=')[0]
    try:
        importlib.import_module(name)
    except Exception:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", pkg])

for pkg, imp in [
    ("earthengine-api>=1.0.0","ee"),
    ("rasterio>=1.3.9","rasterio"),
    ("geopandas>=0.14","geopandas"),
    ("shapely>=2.0","shapely"),
    ("fiona>=1.9","fiona"),
    ("pyproj>=3.5","pyproj"),
    ("joblib>=1.2","joblib"),
    ("requests>=2.31","requests"),
    ("tqdm>=4.66","tqdm"),
]:
    try:
        importlib.import_module(imp)
    except Exception:
        _ensure(pkg, imp)

warnings.filterwarnings("ignore")
os.environ["CPL_DEBUG"] = "OFF"

# ---------------------- CONFIGURAÇÃO ----------------------
# PROCESSAMENTO COMPLETO (2001–2024), TODOS OS MESES
START_YEAR = 2001
END_YEAR   = 2024
MONTHS_TO_PROCESS = list(range(1, 13))  # 1..12

PAD_DAYS   = 2
COMPOSITE  = "median"

EE_PROJECT = os.environ.get("EE_PROJECT", "ee-enneralcantarabariri")

SHP_PATH   = "/content/Hydro_lakes_AM_basin.shp"
USE_JRC_WATER  = False
JRC_OCC_THRESH = 5  # (não usado com USE_JRC_WATER=False)

# Tiles grandes para reduzir chamadas
TILE_DEG      = 1.0
MIN_TILE_DEG  = 0.5  # (mantido para eventual uso futuro)

TARGET_CRS   = "EPSG:3857"
TARGET_SCALE = 1000  # 1 km

# Modelo
MODEL_PATH    = "/content/artifacts_amazonia/amazonia_svr_global.pkl"
PRED_INVERSE  = "ln1p"
NODATA_PRED   = -9999.0

# Paralelização
MAX_WORKERS     = 4  # downloads
PROCESS_WORKERS = 2  # predições

# Pastas
ART_DIR  = Path("/content/artifacts_amazonia_modis"); ART_DIR.mkdir(exist_ok=True, parents=True)
FEATURES_DIR = ART_DIR/"features"; FEATURES_DIR.mkdir(exist_ok=True, parents=True)
TMP_DIR  = ART_DIR/"tmp"; TMP_DIR.mkdir(exist_ok=True, parents=True)
PRED_DIR = ART_DIR/"pred"; PRED_DIR.mkdir(exist_ok=True, parents=True)
PLOT_DIR = ART_DIR/"plots"; PLOT_DIR.mkdir(exist_ok=True, parents=True)
CACHE_DIR = ART_DIR/"cache"; CACHE_DIR.mkdir(exist_ok=True, parents=True)

# Cache de ROI/tiles
TILES_CACHE_PATH = CACHE_DIR / "valid_tiles.pkl"

SR_BANDS = ["sur_refl_b01","sur_refl_b02","sur_refl_b03","sur_refl_b04","sur_refl_b05","sur_refl_b06","sur_refl_b07"]

# ---------------------- UTILS ----------------------
def info(x): print(f"[INFO] {x}")
def err(x):  print(f"[ERROR] {x}")

# ---------------------- EE init ----------------------
def ee_init():
    try:
        ee.Initialize(project=EE_PROJECT)
    except Exception:
        ee.Authenticate(auth_mode='notebook')
        ee.Initialize(project=EE_PROJECT)
    info(f"EE OK — project: {EE_PROJECT}")

# ---------------------- Processados ----------------------
def get_processed_months():
    processed = []
    if PRED_DIR.exists():
        for f in PRED_DIR.glob("amazonia_chla_*.tif"):
            try:
                year, month = f.stem.split("_")[-1].split("-")
                processed.append((int(year), int(month)))
            except:  # ignora nomes fora do padrão
                continue
    return set(processed)

# ---------------------- ROI com cache ----------------------
def load_roi_local():
    roi_cache = CACHE_DIR / "roi_cache.pkl"
    if roi_cache.exists():
        with open(roi_cache, 'rb') as f:
            roi_gdf, roi_geom, roi_bbox_ee = pickle.load(f)
            info(f"ROI carregada do cache: {roi_geom.bounds}")
            return roi_gdf, roi_geom, roi_bbox_ee

    if not Path(SHP_PATH).exists():
        raise FileNotFoundError(f"Shapefile não encontrado: {SHP_PATH}")

    with fiona.Env(SHAPE_RESTORE_SHX='YES'):
        gdf = gpd.read_file(SHP_PATH)
    if gdf.crs is None or str(gdf.crs).upper() != "EPSG:4326":
        gdf = gdf.to_crs("EPSG:4326")

    geoms = []
    for geom in gdf.geometry:
        if geom is None or geom.is_empty: 
            continue
        try:
            gv = make_valid(geom)
        except Exception:
            gv = geom.buffer(0)
        if gv.is_empty: 
            continue
        geoms.append(gv)

    if not geoms:
        raise ValueError("ROI sem geometrias válidas.")

    uni = unary_union(geoms)
    if uni.is_empty:
        raise ValueError("ROI união vazia.")

    xmin,ymin,xmax,ymax = uni.bounds
    roi_bbox_ee = ee.Geometry.Rectangle([xmin,ymin,xmax,ymax], proj="EPSG:4326", geodesic=False)
    gdf_ok = gpd.GeoDataFrame(geometry=[uni], crs="EPSG:4326")

    with open(roi_cache, 'wb') as f:
        pickle.dump((gdf_ok, uni, roi_bbox_ee), f)

    info(f"ROI bounds: {uni.bounds}")
    return gdf_ok, uni, roi_bbox_ee

# ---------------------- Tiles ----------------------
def tiles_rects(bounds, step_deg):
    xmin,ymin,xmax,ymax = bounds
    xs = np.arange(np.floor(xmin/step_deg)*step_deg, np.ceil(xmax/step_deg)*step_deg, step_deg)
    ys = np.arange(np.floor(ymin/step_deg)*step_deg, np.ceil(ymax/step_deg)*step_deg, step_deg)
    rects = []
    for x0 in xs:
        x1 = min(x0+step_deg, xmax)
        for y0 in ys:
            y1 = min(y0+step_deg, ymax)
            if x1<=x0 or y1<=y0: 
                continue
            rects.append((float(x0), float(y0), float(x1), float(y1)))
    return rects

def filter_tiles_simple(roi_geom, rects):
    cand = [r for r in rects if box(*r).intersects(roi_geom)]
    info(f"Tiles válidos (intersecção ROI): {len(cand)}")
    return cand

# ---------------------- QA rápido+ ----------------------
def scale_qc_fast(img):
    sr = img.select(SR_BANDS).multiply(0.0001)

    band_names = img.bandNames()
    has_qc_500 = band_names.indexOf("sur_refl_qc_500m").neq(-1)
    has_state1 = band_names.indexOf("state_1km").neq(-1)

    def _mask_with_state_and_qc():
        qa = img.select("sur_refl_qc_500m")
        good_qc = qa.bitwiseAnd(3).lte(1)  # 0=good, 1=probably good
        st = img.select("state_1km")
        cloud_state = st.bitwiseAnd(3)     # bits 0-1
        clear = cloud_state.eq(0)          # 0=clear
        return sr.updateMask(good_qc.And(clear))

    def _mask_with_qc_only():
        qa = img.select("sur_refl_qc_500m")
        good_qc = qa.bitwiseAnd(3).lte(1)
        return sr.updateMask(good_qc)

    def _no_qc():
        return sr  # fallback

    result = ee.Algorithms.If(
        has_state1,
        _mask_with_state_and_qc(),
        ee.Algorithms.If(has_qc_500, _mask_with_qc_only(), _no_qc())
    )
    return ee.Image(result).copyProperties(img, ['system:time_start'])

# ---------------------- Mosaico mensal (Terra MOD09A1) ----------------------
def build_mosaic_month_fast(roi_bbox_ee, year, month):
    start = ee.Date.fromYMD(year, month, 1)
    end   = start.advance(1, "month")
    if PAD_DAYS > 0:
        start = start.advance(-PAD_DAYS, "day")
        end   = end.advance(PAD_DAYS, "day")

    # Prefer 061; fallback 006
    try:
        mod = ee.ImageCollection("MODIS/061/MOD09A1").filterDate(start, end)
        ic = mod.filterBounds(roi_bbox_ee).map(scale_qc_fast)
    except Exception:
        mod = ee.ImageCollection("MODIS/006/MOD09A1").filterDate(start, end)
        ic = mod.filterBounds(roi_bbox_ee).map(scale_qc_fast)

    mos = ic.select(SR_BANDS)
    mos = mos.median() if COMPOSITE == "median" else mos.mean()
    return mos.clip(roi_bbox_ee)

# ---------------------- Features (proxies por interpolação) ----------------------
def _lin_interp(img_low, wl_low, img_high, wl_high, wl_target):
    frac = (wl_target - wl_low) / (wl_high - wl_low + 1e-12)
    return img_low.add(img_high.subtract(img_low).multiply(frac))

def build_features_image_fast(mosaic, feature_names):
    base = {b: mosaic.select(b) for b in SR_BANDS}
    b03 = base.get("sur_refl_b03")  # ~469 nm
    b04 = base.get("sur_refl_b04")  # ~555 nm
    b01 = base.get("sur_refl_b01")  # ~645 nm

    Rrs_560 = b04
    Rrs_490 = _lin_interp(b03, 469.0, b04, 555.0, 490.0) if (b03 and b04) else None
    Rrs_510 = _lin_interp(b03, 469.0, b04, 555.0, 510.0) if (b03 and b04) else None
    Rrs_443 = _lin_interp(b03, 469.0, b04, 555.0, 443.0).max(0) if (b03 and b04) else None
    Rrs_620 = _lin_interp(b04, 555.0, b01, 645.0, 620.0) if (b01 and b04) else None
    Rrs_665 = _lin_interp(b04, 555.0, b01, 645.0, 665.0) if (b01 and b04) else None
    Rrs_709 = _lin_interp(b04, 555.0, b01, 645.0, 709.0) if (b01 and b04) else None

    proxies = {
        "Rrs_443": Rrs_443, "Rrs_490": Rrs_490, "Rrs_510": Rrs_510,
        "Rrs_560": Rrs_560, "Rrs_620": Rrs_620, "Rrs_665": Rrs_665, "Rrs_709": Rrs_709
    }

    # L1 = soma das bandas originais
    L1 = mosaic.select(SR_BANDS).reduce(ee.Reducer.sum()).add(1e-12)

    def pick(stem):
        table = {
            **proxies,
            "G_over_B": b04.divide(b03.add(1e-12)) if (b04 and b03) else None,
            "B_over_R": b03.divide(b01.add(1e-12)) if (b03 and b01) else None,
            "NDCI": (Rrs_709.subtract(b01)).divide(Rrs_709.add(b01).add(1e-12)) if (Rrs_709 and b01) else None,
        }
        return table.get(stem, None)

    bands = []
    zero_img = mosaic.select(0).multiply(0)

    for fname in feature_names:
        img = pick(fname)

        if img is None and fname.endswith("_norm560"):
            stem = fname[:-8]; b = pick(stem)
            if b is not None and Rrs_560 is not None:
                img = b.divide(Rrs_560.add(1e-12))

        elif img is None and fname == "norm_Rrs_L1":
            img = L1

        elif img is None and fname.endswith("_normL1"):
            stem = fname[:-7]; b = pick(stem)
            if b is not None:
                img = b.divide(L1)

        if img is None:
            img = zero_img

        bands.append(img.rename(fname))

    return ee.Image.cat(bands)

# ---------------------- Download (region memoizado) ----------------------
def _region_polygon_from_rect(rect):
    x0,y0,x1,y1 = rect
    return {"type": "Polygon", "coordinates": [[[x0,y0],[x1,y0],[x1,y1],[x0,y1],[x0,y0]]]}

def download_tiles_parallel(feats_im, rects, ym):
    regions = [_region_polygon_from_rect(r) for r in rects]
    args = []
    for tid, (rect, region) in enumerate(zip(rects, regions)):
        out_tif = FEATURES_DIR / f"feats_{ym}_t{tid:03d}.tif"
        args.append((feats_im, region, str(out_tif)))

    def _dl(arg):
        img, region_geojson, out_path = arg
        params = {
            "region": region_geojson,
            "crs": TARGET_CRS,
            "scale": TARGET_SCALE,
            "maxPixels": int(1e13),
            "format": "GEO_TIFF",
            "resampling": "bilinear"
        }
        max_retries = 2
        for attempt in range(max_retries):
            try:
                url = img.getDownloadURL(params)
                r = requests.get(url, timeout=300, allow_redirects=True)
                r.raise_for_status()
                data = r.content
                if data[:2] == b'PK':
                    with zipfile.ZipFile(io.BytesIO(data)) as zf:
                        names = [n for n in zf.namelist() if n.lower().endswith(('.tif','.tiff'))]
                        if names:
                            with zf.open(names[0]) as zt, open(out_path, 'wb') as f:
                                f.write(zt.read())
                            return str(out_path)
                else:
                    with open(out_path, 'wb') as f:
                        f.write(data)
                    return str(out_path)
            except Exception as e:
                if attempt == max_retries - 1:
                    err(f"Download falhou após {max_retries} tentativas: {e}")
                else:
                    time.sleep(1)
        return None

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
        results = list(tqdm(ex.map(_dl, args), total=len(args), desc="Downloading tiles"))

    return [r for r in results if r is not None]

# ---------------------- Predição ----------------------
def predict_tile_fast(args):
    path_tif, roi_gdf, roi_geom, model_data = args
    try:
        with rio.open(path_tif) as ds:
            arr = ds.read().astype("float32")  # (B,H,W)
            prof = ds.profile
            height, width = ds.height, ds.width
            transform = ds.transform
            crs = ds.crs

        # Máscara válida: todos os bands finitos
        finite_all = np.isfinite(arr).all(axis=0)

        # ROI mask
        try:
            geoms_tx = [transform_geom("EPSG:4326", crs.to_string(), mapping(roi_geom), precision=6)]
            roi_m = rasterize(
                [(g,1) for g in geoms_tx],
                out_shape=(height, width),
                transform=transform,
                fill=0, all_touched=True, dtype="uint8"
            ).astype(bool)
        except Exception:
            roi_m = np.ones((height, width), dtype=bool)

        mask = finite_all & roi_m
        if not mask.any():
            return None

        B,H,W = arr.shape
        data = arr.reshape(B, -1).T
        valid_idx = mask.reshape(-1)

        y_log = np.full(data.shape[0], np.nan, dtype="float32")
        if valid_idx.any():
            X = data[valid_idx]
            finite = np.isfinite(X).all(axis=1)
            if finite.any():
                Xc = X[finite]
                valid_finite_idx = np.where(valid_idx)[0][finite]
                y_log[valid_finite_idx] = model_data["model"].predict(Xc).astype("float32")

        # Inverse transform
        if PRED_INVERSE == "ln1p":
            y_lin = np.expm1(y_log)
        else:
            y_lin = y_log

        pred = y_lin.reshape(H,W).astype("float32")
        pred[~mask] = NODATA_PRED
        pred[~np.isfinite(pred)] = NODATA_PRED

        out_tile = TMP_DIR / f"pred_{Path(path_tif).stem}.tif"
        prof_out = {
            "driver":"GTiff","height":H,"width":W,"count":1,"dtype":"float32",
            "crs": crs, "transform": transform, "nodata": NODATA_PRED,
            "compress":"deflate"
        }
        with rio.open(out_tile, "w", **prof_out) as dst:
            dst.write(pred, 1)

        return str(out_tile)

    except Exception as e:
        err(f"Erro predição {path_tif}: {e}")
        return None

def predict_tiles_parallel(downloaded, roi_gdf, roi_geom, M):
    predict_args = [(f, roi_gdf, roi_geom, M) for f in downloaded]
    with ProcessPoolExecutor(max_workers=PROCESS_WORKERS) as executor:
        results = list(tqdm(
            executor.map(predict_tile_fast, predict_args),
            total=len(predict_args),
            desc="Predicting tiles"
        ))
    return [r for r in results if r is not None]

# ---------------------- Preview rápido ----------------------
def preview_png_fast(tif_path):
    try:
        with rio.open(tif_path) as ds:
            arr = ds.read(1, out_shape=(max(1, ds.height//4), max(1, ds.width//4)))
            arr = np.ma.masked_equal(arr, ds.nodata)

        if arr.compressed().size == 0:
            return

        vmin, vmax = np.percentile(arr.compressed(), (5, 95))

        plt.figure(figsize=(6, 4))
        plt.imshow(arr, vmin=vmin, vmax=vmax, cmap="viridis")
        plt.colorbar(label="Chl-a (mg m$^{-3}$)", shrink=0.6)
        plt.title(Path(tif_path).name, fontsize=10)
        plt.axis('off')

        out = PLOT_DIR / f"preview_{Path(tif_path).stem}.png"
        plt.savefig(out, dpi=100, bbox_inches="tight")
        plt.close()

    except Exception as e:
        err(f"Preview error: {e}")

# ---------------------- MAIN ----------------------
def main():
    start_time = time.time()
    ee_init()

    # ROI (cache)
    roi_gdf, roi_geom, roi_bbox_ee = load_roi_local()

    # Modelo
    if not Path(MODEL_PATH).exists():
        raise FileNotFoundError(f"Modelo não encontrado: {MODEL_PATH}")
    M = joblib.load(MODEL_PATH)

    # Tiles (com cache simples de contagem, se quiser evoluir)
    rects_all = tiles_rects(roi_geom.bounds, TILE_DEG)
    rects = filter_tiles_simple(roi_geom, rects_all)
    info(f"Processando tiles de {TILE_DEG}° — total: {len(rects)}")

    # Meses já processados
    processed = get_processed_months()

    # Lista de meses a processar
    months_todo = []
    for year in range(START_YEAR, END_YEAR + 1):
        for month in MONTHS_TO_PROCESS:
            if (year, month) not in processed:
                months_todo.append((year, month))

    info(f"Meses a processar: {len(months_todo)} (pular: {len(processed)}) - MODIS 2001–2024")

    if not months_todo:
        info("Todos os meses já foram processados!")
        return

    processed_count = 0

    for year, month in months_todo:
        ym = f"{year:04d}-{month:02d}"

        # Guarda de disponibilidade do MODIS/061 (não dispara com START_YEAR=2001, mas é seguro)
        if (year < 2000) or (year == 2000 and month < 2):
            info(f"[{ym}] Sem dados MOD09A1/061 — pulando.")
            continue

        # Janela de execução (economiza chamadas quando o tempo estoura)
        elapsed_h = (time.time() - start_time) / 3600
        if elapsed_h > 8.5:
            info(f"Parando por limite de tempo. Processados: {processed_count}")
            break

        info(f"=== {ym} === ({processed_count+1}/{len(months_todo)})")

        out_path = PRED_DIR / f"amazonia_chla_{ym}.tif"
        if out_path.exists():
            info(f"[{ym}] Já existe, pulando...")
            processed_count += 1
            continue

        try:
            # Features
            mosaic = build_mosaic_month_fast(roi_bbox_ee, year, month)
            feats_im = build_features_image_fast(mosaic, M["features"])

            # Download paralelo
            downloaded = download_tiles_parallel(feats_im, rects, ym)
            if not downloaded:
                err(f"[{ym}] Nenhum download bem-sucedido")
                continue
            info(f"[{ym}] Downloads: {len(downloaded)}")

            # Predição paralela
            pred_tiles = predict_tiles_parallel(downloaded, roi_gdf, roi_geom, M)
            if not pred_tiles:
                err(f"[{ym}] Nenhuma predição bem-sucedida")
                continue
            info(f"[{ym}] Predições: {len(pred_tiles)}")

            # Merge final
            srcs = [rio.open(p) for p in pred_tiles]
            mosaic_arr, mosaic_trans = rio_merge(srcs, nodata=NODATA_PRED)
            for s in srcs: 
                s.close()

            meta = {
                "driver": "GTiff",
                "height": mosaic_arr.shape[1],
                "width":  mosaic_arr.shape[2],
                "count":  1,
                "dtype":  mosaic_arr.dtype,
                "crs":    TARGET_CRS,
                "transform": mosaic_trans,
                "nodata": NODATA_PRED,
                "compress": "lzw",
                "tiled": True
            }
            with rio.open(out_path, "w", **meta) as dst:
                dst.write(mosaic_arr[0], 1)

            # Preview a cada 5 meses
            if processed_count % 5 == 0:
                preview_png_fast(out_path)

            # Limpeza de temporários
            for p in downloaded + pred_tiles:
                try:
                    Path(p).unlink(missing_ok=True)
                except Exception:
                    pass

            processed_count += 1
            elapsed = (time.time() - start_time) / 3600
            info(f"[{ym}] OK! Tempo acumulado: {elapsed:.1f}h")

        except Exception as e:
            err(f"[{ym}] Erro: {e}")
            continue

    total_time = (time.time() - start_time) / 3600
    info(f"CONCLUÍDO! Processados: {processed_count} meses em {total_time:.1f}h")

# ---------------------- ENTRYPOINT ----------------------
if __name__ == "__main__":
    main()
