# ============================================================
# AMAZÔNIA — Export mensal com REGIÕES INTELIGENTES + GCS/Drive + retomada
# - Particiona a ROI (convex-hulls por clusters) ⇒ MUITO menos tasks
# - Filtra por água (JRC) por região/mês
# - Exporta para GCS (recomendado) ou Drive, com backoff + retomada
# - Features na ordem do seu modelo (pickle)
# - "predict" local compatível com os GeoTIFFs exportados
# ============================================================

# !pip -q install earthengine-api rasterio joblib numpy matplotlib geopandas shapely fiona pyproj requests scikit-learn google-api-python-client

import os, warnings, sys, subprocess, importlib, time, json, random, math
from pathlib import Path
import numpy as np
import matplotlib; matplotlib.use("Agg")
import matplotlib.pyplot as plt

def _ensure(pkg, imp=None):
    name = imp or pkg.split('==')[0].split('>=')[0]
    try:
        importlib.import_module(name)
    except Exception:
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", pkg])

for pkg, imp in [
    ("earthengine-api>=1.0.0","ee"),
    ("rasterio>=1.3.9","rasterio"),
    ("geopandas>=0.14","geopandas"),
    ("shapely>=2.0","shapely"),
    ("fiona>=1.9","fiona"),
    ("pyproj>=3.5","pyproj"),
    ("joblib>=1.2","joblib"),
    ("requests>=2.31","requests"),
    ("scikit-learn>=1.3","sklearn"),
    ("google-api-python-client>=2.129","googleapiclient"),
]:
    _ensure(pkg, imp)

warnings.filterwarnings("ignore")
os.environ["CPL_DEBUG"] = "OFF"
import logging
logging.getLogger("googleapiclient.http").setLevel(logging.ERROR)

import ee, joblib, geopandas as gpd, fiona, rasterio as rio
from rasterio.merge import merge as rio_merge
from rasterio.warp import transform_geom
from rasterio.features import rasterize
from rasterio.plot import plotting_extent
from shapely.geometry import box, mapping, Point
from shapely.ops import unary_union
from shapely.validation import make_valid
from sklearn.cluster import MiniBatchKMeans
from googleapiclient.errors import HttpError

# ---------------- CONFIG ----------------
MODE                  = "export"       # "export" | "predict"

EE_PROJECT            = os.environ.get("EE_PROJECT", "ee-enneralcantarabariri")
SHP_PATH              = "/content/Hydro_lakes_AM_basin.shp"   # shapefile da planície/espelho d'água

# Período
START_YEAR            = 2001
END_YEAR              = 2024
MONTHS_FILTER         = None           # ex.: [6,12] para testar

# MODIS composição
USE_8DAY              = True
PAD_DAYS              = 4
COMPOSITE             = "median"       # "median" | "mean"

# Água/mascara server-side
USE_JRC_WATER         = True
JRC_OCC_THRESH        = 5              # %

# Export
TARGET_CRS            = "EPSG:4326"
TARGET_SCALE          = 500            # m
EXPORT_TO             = "GCS"          # "GCS" | "DRIVE"
GCS_BUCKET            = "meu-bucket-amazonia"   # <<< EDITE AQUI se usar GCS
DRIVE_FOLDER          = "amazonia_features"
MAX_PIXELS            = int(1e13)

# Modelo (ordem das features)
MODEL_PATH            = "/content/artifacts_amazonia/amazonia_svr_global.pkl"
PRED_INVERSE          = "ln1p"
NODATA_PRED           = -9999.0

# Regiões inteligentes
N_REGIONS             = 20             # ~20 regiões ⇒ ~20 tasks/mês
SAMPLE_STEP_KM        = 10             # amostragem ~10 km p/ clustering

# Fila/backoff
MAX_TASKS_PER_RUN     = 1500
QUEUE_WATERMARK       = 2600
START_BACKOFF_SEC     = 1.0
MAX_BACKOFF_SEC       = 30.0

# Pastas locais
ART_DIR               = Path("/content/artifacts_amazonia_modis"); ART_DIR.mkdir(exist_ok=True, parents=True)
PRED_DIR              = ART_DIR/"pred";  PRED_DIR.mkdir(exist_ok=True, parents=True)
PLOT_DIR              = ART_DIR/"plots"; PLOT_DIR.mkdir(exist_ok=True, parents=True)
TMP_DIR               = ART_DIR/"tmp";   TMP_DIR.mkdir(exist_ok=True, parents=True)
STATE_DIR             = ART_DIR/"state"; STATE_DIR.mkdir(exist_ok=True, parents=True)  # retomada

# MODIS bands
SR_BANDS              = ["sur_refl_b01","sur_refl_b02","sur_refl_b03","sur_refl_b04","sur_refl_b05","sur_refl_b06","sur_refl_b07"]
QA_BAND_500M          = "sur_refl_qc_500m"

# ---------------- Utils básicos ----------------
def _err(x): print(x)

def ee_init():
    try: ee.Initialize(project=EE_PROJECT)
    except Exception:
        ee.Authenticate(auth_mode='notebook'); ee.Initialize(project=EE_PROJECT)

# ---------- ROI ----------
def load_roi():
    if not Path(SHP_PATH).exists():
        raise FileNotFoundError(f"[ROI] Shapefile não encontrado: {SHP_PATH}")
    with fiona.Env(SHAPE_RESTORE_SHX='YES'):
        gdf = gpd.read_file(SHP_PATH)
    if gdf.crs is None or str(gdf.crs).upper() != "EPSG:4326":
        gdf = gdf.to_crs("EPSG:4326")
    geoms=[]
    for g in gdf.geometry:
        if g is None or g.is_empty: continue
        try: gv = make_valid(g)
        except Exception: gv = g.buffer(0)
        if gv.is_empty: continue
        geoms.append(gv)
    if not geoms: raise ValueError("[ROI] Geometrias inválidas.")
    uni = unary_union(geoms)
    xmin,ymin,xmax,ymax = uni.bounds
    # Vamos NUNCA enviar a ROI complexa ao EE (apenas retângulos)
    roi_rect_ee = ee.Geometry.Rectangle([xmin,ymin,xmax,ymax], proj="EPSG:4326", geodesic=False)
    return gpd.GeoDataFrame(geometry=[uni], crs="EPSG:4326"), uni, roi_rect_ee

# ---------- REGIÕES INTELIGENTES ----------
def approx_deg_for_km(km):  # ~ no equador
    return km / 111.32

def lonlat_grid(bounds, step_deg):
    xmin,ymin,xmax,ymax = bounds
    xs = np.arange(xmin, xmax, step_deg)
    ys = np.arange(ymin, ymax, step_deg)
    pts=[]
    for x in xs:
        for y in ys:
            pts.append((x+step_deg/2, y+step_deg/2))
    return np.array(pts) if pts else np.empty((0,2))

def partition_roi_regions(roi_geom, n_regions=N_REGIONS, sample_step_km=SAMPLE_STEP_KM):
    step_deg = approx_deg_for_km(sample_step_km)
    grid = lonlat_grid(roi_geom.bounds, step_deg)
    inside = []
    if grid.size:
        for x,y in grid:
            if roi_geom.contains(Point(x,y)):
                inside.append([x,y])
    # se poucos pontos, cai para 1 região (a própria ROI)
    if len(inside) < max(10, n_regions*3):
        return [roi_geom]
    X = np.array(inside)
    k = min(n_regions, len(X)//10)
    if k < 2:
        return [roi_geom]
    mbk = MiniBatchKMeans(n_clusters=k, random_state=42, batch_size=2048, n_init="auto")
    labels = mbk.fit_predict(X)
    regions=[]
    for cid in range(k):
        pts = X[labels==cid]
        if pts.shape[0] < 3: continue
        poly = gpd.GeoSeries([Point(px,py) for px,py in pts]).unary_union.convex_hull
        inter = poly.intersection(roi_geom)
        if inter.is_empty: continue
        if inter.area < 1e-8: continue
        regions.append(inter)
    return regions or [roi_geom]

# ---------- JRC filtro por região ----------
def has_water_in_region(region_poly, thresh=JRC_OCC_THRESH):
    try:
        x0,y0,x1,y1 = region_poly.bounds
        region_ee = ee.Geometry.Rectangle([x0,y0,x1,y1], proj="EPSG:4326", geodesic=False)
        jrc = ee.Image("JRC/GSW1_4/GlobalSurfaceWater").select("occurrence").gte(thresh)
        s = jrc.reduceRegion(ee.Reducer.sum(), geometry=region_ee, scale=TARGET_SCALE, maxPixels=1e12)
        val = s.get("occurrence").getInfo()
        return (val or 0) > 0
    except Exception:
        # fallback permissivo (não bloqueia)
        return True

# ---------- MODIS ----------
def build_collection_month(roi_rect_ee, year, month):
    start = ee.Date.fromYMD(year, month, 1)
    end   = start.advance(1, "month")
    if PAD_DAYS>0:
        start = start.advance(-PAD_DAYS, "day")
        end   = end.advance(PAD_DAYS, "day")

    if USE_8DAY:
        mod = ee.ImageCollection("MODIS/061/MOD09A1").filterDate(start, end)
        myd = ee.ImageCollection("MODIS/061/MYD09A1").filterDate(start, end)
    else:
        mod = ee.ImageCollection("MODIS/061/MOD09GA").filterDate(start, end)
        myd = ee.ImageCollection("MODIS/061/MYD09GA").filterDate(start, end)

    def scale_qc(img):
        sr = img.select(SR_BANDS).multiply(0.0001)
        bn = img.bandNames()
        qa = ee.Image(ee.Algorithms.If(bn.contains(QA_BAND_500M), img.select(QA_BAND_500M), ee.Image(0)))
        sr = sr.updateMask(qa.bitwiseAnd(3).lte(1))  # Ideal/Good
        return sr

    ic = mod.merge(myd).filterBounds(roi_rect_ee).map(scale_qc)
    mos = ic.select(SR_BANDS)
    mos = mos.mean() if COMPOSITE=="mean" else mos.median()

    if USE_JRC_WATER:
        jrc = ee.Image("JRC/GSW1_4/GlobalSurfaceWater").select("occurrence")
        water = jrc.gte(JRC_OCC_THRESH)
        mos = mos.updateMask(water)

    return mos.clip(roi_rect_ee).reproject(TARGET_CRS, None, TARGET_SCALE)

# ---------- Features (ordem do modelo) ----------
MODIS_TO_RRS = {
    "Rrs_443":"sur_refl_b03",
    "Rrs_490":"sur_refl_b03",
    "Rrs_510":"sur_refl_b04",
    "Rrs_560":"sur_refl_b04",
    "Rrs_620":"sur_refl_b01",
    "Rrs_665":"sur_refl_b01",
}

def build_features_image(mosaic, feature_names):
    base = {b: mosaic.select(b) for b in SR_BANDS}
    proxies = {k: base[v] for k,v in MODIS_TO_RRS.items() if v in base}
    def safe_add(lst):
        if not lst: return None
        out = lst[0]
        for im in lst[1:]: out = out.add(im)
        return out
    L1 = safe_add([base[b] for b in SR_BANDS]).add(1e-12)

    Rrs_709=None
    if all(b in base for b in ("sur_refl_b01","sur_refl_b04")):
        lam1,lam2,lamT=560.0,665.0,709.0
        slope=base["sur_refl_b01"].subtract(base["sur_refl_b04"]).divide((lam2-lam1)+1e-12)
        Rrs_709=base["sur_refl_b04"].add(slope.multiply(lamT-lam1)).max(0)

    def lerp(l):
        if (Rrs_709 is None) or ("sur_refl_b01" not in base): return None
        t=(l-665.0)/(709.0-665.0)
        return base["sur_refl_b01"].add(Rrs_709.subtract(base["sur_refl_b01"]).multiply(t)).max(0)

    Rrs_681, Rrs_700, Rrs_705, Rrs_708 = lerp(681.0), lerp(700.0), lerp(705.0), lerp(708.0)

    def pick(stem):
        table={
            "Rrs_681":Rrs_681,"Rrs_700":Rrs_700,"Rrs_705":Rrs_705,"Rrs_708":Rrs_708,"Rrs_709":Rrs_709,
            "Rrs_443":proxies.get("Rrs_443"),"Rrs_490":proxies.get("Rrs_490"),
            "Rrs_510":proxies.get("Rrs_510"),"Rrs_560":proxies.get("Rrs_560"),
            "Rrs_620":proxies.get("Rrs_620"),"Rrs_665":proxies.get("Rrs_665"),
        }
        return table.get(stem,None)

    bands=[]
    for fname in feature_names:
        img=pick(fname)

        if img is None and fname.endswith("_norm560"):
            stem=fname[:-8]; b=pick(stem)
            if b is not None and proxies.get("Rrs_560") is not None: img=b.divide(proxies["Rrs_560"].add(1e-12)).rename(fname)
        if img is None and fname.endswith("_norm547"):
            stem=fname[:-8]; b=pick(stem)
            if b is not None and base.get("sur_refl_b04") is not None: img=b.divide(base["sur_refl_b04"].add(1e-12)).rename(fname)
        if img is None and fname=="norm_Rrs_L1": img=L1.rename(fname)
        if img is None and fname.endswith("_normL1"):
            stem=fname[:-7]; b=pick(stem)
            if b is not None: img=b.divide(L1).rename(fname)

        if img is None and fname=="G_over_B" and base.get("sur_refl_b04") is not None and base.get("sur_refl_b03") is not None:
            img = base["sur_refl_b04"].divide(base["sur_refl_b03"].add(1e-12)).rename(fname)
        if img is None and fname=="B_over_R" and base.get("sur_refl_b03") is not None and base.get("sur_refl_b01") is not None:
            img = base["sur_refl_b03"].divide(base["sur_refl_b01"].add(1e-12)).rename(fname)
        if img is None and fname=="NDCI" and (Rrs_709 is not None) and base.get("sur_refl_b01") is not None:
            img = Rrs_709.subtract(base["sur_refl_b01"]).divide(Rrs_709.add(base["sur_refl_b01"]).add(1e-12)).rename(fname)
        if img is None and fname=="Red_a":
            if (Rrs_681 is not None) and base.get("sur_refl_b01") is not None:
                img = (Rrs_681.subtract(base["sur_refl_b01"])).divide(Rrs_681.add(base["sur_refl_b01"]).add(1e-12)).rename(fname)
            else:
                img = ee.Image(0).rename(fname)
        if img is None and fname=="RedEdgeSlope":
            if (Rrs_709 is not None) and (Rrs_681 is not None): img = Rrs_709.subtract(Rrs_681).rename(fname)
            elif (Rrs_709 is not None): img = Rrs_709.subtract(base["sur_refl_b01"]).rename(fname)
        if img is None and fname=="Area_Blue" and base.get("sur_refl_b03") is not None:  img = base["sur_refl_b03"].rename(fname)
        if img is None and fname=="Area_Green" and base.get("sur_refl_b04") is not None: img = base["sur_refl_b04"].rename(fname)
        if img is None and fname=="Area_Red"  and base.get("sur_refl_b01") is not None: img = base["sur_refl_b01"].rename(fname)
        if img is None and fname=="Area_RE"   and (Rrs_709 is not None): img = Rrs_709.rename(fname)

        if img is None: img = ee.Image(0).rename(fname)
        bands.append(img)

    return ee.Image.cat(bands).reproject(TARGET_CRS, None, TARGET_SCALE)

# ---------- fila & backoff ----------
def count_active_tasks():
    try:
        return sum(1 for t in ee.batch.Task.list() if t.status().get('state','') in ('READY','RUNNING'))
    except Exception: return 0

def _start_task_with_backoff(make_task_fn, desc):
    backoff = START_BACKOFF_SEC
    while True:
        try:
            task = make_task_fn()
            task.start()
            return True
        except HttpError as e:
            msg = str(e)
            if any(s in msg for s in ["Too many tasks","503","quota","Rate Limit"]):
                time.sleep(min(backoff + random.uniform(0, backoff/3), MAX_BACKOFF_SEC))
                backoff = min(backoff*1.8, MAX_BACKOFF_SEC)
                continue
            _err(f"[start] {desc}: {msg}")
            return False
        except Exception as e:
            _err(f"[start] {desc}: {e}")
            return False

# ---------- retomada ----------
def done_marker(desc):
    return STATE_DIR / f"{desc}.started"

def already_marked(desc):
    return done_marker(desc).exists()

def mark_started(desc):
    m = done_marker(desc)
    try:
        m.write_text("started")
    except Exception:
        pass

# ---------- enqueue usando regiões ----------
def enqueue_exports_regions(roi_rect_ee, roi_geom, feature_names):
    # gera regiões
    regions = partition_roi_regions(roi_geom, N_REGIONS, SAMPLE_STEP_KM)
    # filtra por água (rápido, por bounds)
    regions = [r for r in regions if has_water_in_region(r, JRC_OCC_THRESH)]
    if not regions: regions = [roi_geom]

    years = range(START_YEAR, END_YEAR+1)
    months = MONTHS_FILTER if MONTHS_FILTER else range(1,13)
    enqueued=0

    for y in years:
        for m in months:
            ym = f"{y:04d}-{m:02d}"
            try:
                mosaic = build_collection_month(roi_rect_ee, y, m)
                feats_im = build_features_image(mosaic, feature_names)
            except Exception as e:
                _err(f"[{ym}] build features: {e}")
                continue

            for ridx, reg in enumerate(regions):
                if count_active_tasks() >= QUEUE_WATERMARK or enqueued >= MAX_TASKS_PER_RUN:
                    return enqueued
                x0,y0,x1,y1 = reg.bounds
                region = ee.Geometry.Rectangle([x0,y0,x1,y1], proj="EPSG:4326", geodesic=False)
                desc   = f"feats_{ym}_r{ridx:02d}"

                # retomada: se já marcamos que tentamos enfileirar, não manda de novo
                if already_marked(desc):
                    continue

                if EXPORT_TO.upper()=="GCS":
                    if not GCS_BUCKET:
                        raise ValueError("Defina GCS_BUCKET para usar EXPORT_TO='GCS'.")
                    def _mk():
                        return ee.batch.Export.image.toCloudStorage(
                            image=feats_im, description=desc, bucket=GCS_BUCKET,
                            fileNamePrefix=f"{DRIVE_FOLDER}/{desc}", region=region,
                            scale=TARGET_SCALE, crs=TARGET_CRS, maxPixels=MAX_PIXELS,
                            fileFormat='GeoTIFF')
                else:
                    def _mk():
                        return ee.batch.Export.image.toDrive(
                            image=feats_im, description=desc, folder=DRIVE_FOLDER,
                            fileNamePrefix=desc, region=region, scale=TARGET_SCALE,
                            crs=TARGET_CRS, maxPixels=MAX_PIXELS, fileFormat='GeoTIFF',
                            formatOptions={'cloudOptimized': True})

                ok = _start_task_with_backoff(_mk, desc)
                if ok:
                    enqueued += 1
                    mark_started(desc)
    return enqueued

# ---------- predict local ----------
def roi_mask_like(ds, roi_gdf, roi_geom):
    geoms_tx = [transform_geom(roi_gdf.crs.to_string(), ds.crs.to_string(), mapping(roi_geom), precision=6)]
    m = rasterize([(g,1) for g in geoms_tx], out_shape=(ds.height, ds.width),
                  transform=ds.transform, fill=0, all_touched=True, dtype="uint8")
    return m.astype(bool)

def inverse_transform(y):
    if PRED_INVERSE=="ln1p": return np.expm1(y)
    if PRED_INVERSE=="log10_1p": return (10.0**y) - 1.0
    return y

def preview_png(tif_path):
    try:
        with rio.open(tif_path) as ds:
            arr = ds.read(1, masked=True); ext = plotting_extent(ds)
        v = arr.compressed()
        vmin,vmax = (np.percentile(v,(2,98)) if v.size else (0,1))
        plt.figure(figsize=(7,6))
        plt.imshow(arr, extent=ext, vmin=vmin, vmax=vmax, cmap="viridis", interpolation="nearest")
        plt.colorbar(label="Chl-a (mg/m³)", shrink=0.8)
        plt.xticks([]); plt.yticks([]); plt.tight_layout()
        out = PLOT_DIR / f"preview_{Path(tif_path).stem}.png"
        plt.savefig(out, dpi=150, bbox_inches="tight"); plt.close()
    except Exception as e:
        _err(f"[preview] {e}")

def predict_local_from_folder(features_root, roi_gdf, roi_geom, model_path=MODEL_PATH):
    if not Path(model_path).exists(): raise FileNotFoundError(f"[MODEL] Não encontrado: {model_path}")
    M = joblib.load(model_path)
    if "model" not in M or "features" not in M: raise ValueError("[MODEL] Estrutura inválida.")
    files = sorted([str(p) for p in Path(features_root).rglob("feats_*.tif")])
    if not files: raise FileNotFoundError(f"[predict] Nenhum GeoTIFF em: {features_root}")

    groups={}
    for f in files:
        st = Path(f).stem  # feats_YYYY-MM_rNN
        parts = st.split("_")
        if len(parts)<3: continue
        ym = parts[1]
        groups.setdefault(ym, []).append(f)

    for ym, paths in sorted(groups.items()):
        tile_preds=[]
        for fpath in sorted(paths):
            try:
                with rio.open(fpath) as ds:
                    B = ds.count
                    arr = ds.read()
                    prof= ds.profile
                    valid = np.ones((arr.shape[1],arr.shape[2]), dtype=bool)
                    for i in range(B): valid &= (ds.read_masks(i+1) > 0)
                    roi_m = roi_mask_like(ds, roi_gdf, roi_geom)
                    total = valid & roi_m
                    data  = arr.reshape(B,-1).T.astype("float32")
                    ylog  = np.full(data.shape[0], np.nan, dtype="float32")
                    msk   = total.reshape(-1)
                    if msk.any():
                        X = data[msk]
                        finite = np.isfinite(X).all(axis=1)
                        if finite.any():
                            idx = np.where(msk)[0][finite]
                            ylog[idx] = M["model"].predict(X[finite]).astype("float32")
                    ylin = inverse_transform(ylog.astype("float64"))
                    pred = ylin.reshape(arr.shape[1],arr.shape[2]).astype("float32")
                    pred[~total] = NODATA_PRED
                    pred[~np.isfinite(pred)] = NODATA_PRED

                    out_tile = TMP_DIR / f"chla_{ym}_{Path(fpath).stem.split('_r')[-1]}.tif"
                    prof_out = prof.copy()
                    prof_out.update(dtype="float32", count=1, nodata=NODATA_PRED,
                                    compress="deflate", tiled=True, BIGTIFF="IF_SAFER")
                    with rio.open(out_tile,"w",**prof_out) as dst: dst.write(pred,1)
                    tile_preds.append(str(out_tile))
            except Exception as e:
                _err(f"[predict {ym}] {e}")

        if not tile_preds: continue
        try:
            srcs=[rio.open(p) for p in tile_preds]
            mosaic_arr, mosaic_trans = rio_merge(srcs, nodata=NODATA_PRED)
            for s in srcs: s.close()
            for p in tile_preds: Path(p).unlink(missing_ok=True)
            out_path = PRED_DIR / f"amazonia_chla_{ym}.tif"
            meta = {"driver":"GTiff","height":mosaic_arr.shape[1],"width":mosaic_arr.shape[2],
                    "count":1,"dtype":mosaic_arr.dtype,"crs":TARGET_CRS,"transform":mosaic_trans,
                    "nodata":NODATA_PRED,"compress":"deflate","tiled":True,"BIGTIFF":"IF_SAFER"}
            with rio.open(out_path,"w",**meta) as dst: dst.write(mosaic_arr[0],1)
            preview_png(out_path)
        except Exception as e:
            _err(f"[merge {ym}] {e}")

# ---------- Main ----------
def main():
    try:
        ee_init()
        roi_gdf, roi_geom, roi_rect_ee = load_roi()

        if MODE.lower()=="export":
            if not Path(MODEL_PATH).exists(): raise FileNotFoundError(f"[MODEL] Não encontrado: {MODEL_PATH}")
            M = joblib.load(MODEL_PATH)
            if "features" not in M: raise ValueError("[MODEL] 'features' ausente.")
            features = list(M["features"])
            enq = enqueue_exports_regions(roi_rect_ee, roi_geom, features)
        elif MODE.lower()=="predict":
            # Ajuste o caminho local onde salvou/copiou os GeoTIFFs de features
            FEATURES_ROOT = "/content/drive/MyDrive/amazonia_features"
            predict_local_from_folder(FEATURES_ROOT, roi_gdf, roi_geom, MODEL_PATH)
        else:
            raise ValueError("MODE deve ser 'export' ou 'predict'.")
    except Exception as e:
        print(f"[fatal] {e}")

if __name__=="__main__":
    main()
